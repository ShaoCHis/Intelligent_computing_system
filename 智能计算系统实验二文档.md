# 智能计算系统实验二文档

实时风格迁移在线推理与离线部署

1952395沈韬

[TOC]



## 实验目的

- 掌握使用TensorFlow定义完整网络结构的方法
- 掌握使用TensorFlow进行神经网络预测的方法
- 理解模型量化的基本原理和方法，具备使用TensorFlow对模型进行量化的能力
- 掌握在DLP上使用TensorFlow对模型进行预测的原理和方法

## 实验内容

- 模型量化:将单精度模型量化为INT8 模型。
- 在线推理，完成MLU 推理代码的移植工作，分别比较三种不同模型(原始模型、 PowerDifference 算子模型，Numpy 算子模型)在CPU 和MLU上的性能和精度。
- 离线推理，完成MLU CNRT 离线推理代码，并完成部署测试。

## 实验步骤

### 模型量化

MLU270 对于mlp和conv等算子可使用int数据类型进行计算以提高效率，所以先要将原始的float32数据类型的pb模型量化成为int类型。

```bash
1. cd /opt/AICSE-demostudent/demo/style_transfer_bcl/tools/fppb_to_intpb
2. python fppb_to_intpb.py udnie_int8.ini
```

生成的模型会保存在/opt/AICSE-demo- student/demo/style_transfer_bcl/models/int_pb_models 目录下。

<img src="/Users/shentao/Library/Application Support/typora-user-images/Screen Shot 2021-12-17 at 12.07.31 PM.png" alt="Screen Shot 2021-12-17 at 12.07.31 PM" style="zoom:50%;" />

### 在线推理程序

分别补全/opt/AICSE-demo-student/demo/style_transfer_bcl/src/online_mlu/transform_mlu.py 和/opt/AICSEdemo- student/demo/style_transfer_bcl/src/online_cpu/transform_cpu.py。比较多种不同推理方式的性能精度差异。

#### CPU在线推理

补全transform_cpu.py

```python
# TODO:完成PowerDifference Pb模型的推理
input_differ = sess.graph.get_tensor_by_name('moments_15/PowerDifference_z:0')
input_tensor = sess.graph.get_tensor_by_name('X_content:0')
output_tensor = sess.graph.get_tensor_by_name('add_37:0')
start_time = time.time()

ret =sess.run(output_tensor, feed_dict={input_differ:2,input_tensor: [X]})
end_time = time.time()

# TODO:完成Numpy版本 Pb模型的推理
input_tensor = sess.graph.get_tensor_by_name('X_content:0')
input_differ = sess.graph.get_tensor_by_name('moments_15/PowerDifference:0')
output_tensor = sess.graph.get_tensor_by_name('add_37:0')
conv_tensor = sess.graph.get_tensor_by_name('Conv2D_13:0')
grad_tensor = sess.graph.get_tensor_by_name('moments_15/StopGradient:0')
temp_feed = {input_differ:[X],input_tensor:[X]}
conv = sess.run(conv_tensor,feed_dict=temp_feed)
grad = sess.run(grad_tensor,feed_dict=temp_feed)
differ = power_diff_numpy(conv,grad,2)
start_time = time.time()
ret =sess.run(output_tensor, feed_dict=
    {input_differ:differ,input_tensor:[X]})
end_time = time.time()
```

运行结果

![Screen Shot 2021-12-17 at 12.12.44 PM](/Users/shentao/Library/Application Support/typora-user-images/Screen Shot 2021-12-17 at 12.12.44 PM.png)

- 原算子模型执行时间：2.58s

  <img src="/Users/shentao/Library/Application Support/typora-user-images/Screen Shot 2021-12-17 at 12.15.56 PM.png" alt="Screen Shot 2021-12-17 at 12.15.56 PM" style="zoom:50%;" />

- 自定义算子模型执行时间：2.22s

  <img src="/Users/shentao/Library/Application Support/typora-user-images/Screen Shot 2021-12-17 at 12.16.26 PM.png" alt="Screen Shot 2021-12-17 at 12.16.26 PM" style="zoom:50%;" />

- numpy算子模型执行时间：2.13s

<img src="/Users/shentao/Library/Application Support/typora-user-images/Screen Shot 2021-12-17 at 12.17.13 PM.png" alt="Screen Shot 2021-12-17 at 12.17.13 PM" style="zoom:50%;" />

#### MLU在线推理

补全transform_mlu.py文件

```python
# TODO:完成MLU Config配置
config.mlu_options.save_offline_model = True 3 
config.mlu_options.data_parallelism = 8
config.mlu_options.model_parallelism = 4
model_name = os.path.basename(args.ori_pb).split(".")[0]
image_name = os.path.basename(args.image).split(".")[0]
config.mlu_options.offline_model_name = '../../models/offline_models/'
    + model_name + '.cambricon'

# TODO:完成PowerDifference Pb模型的推理
input_differ = sess.graph.get_tensor_by_name('moments_15/PowerDifference_z:0')
input_tensor = sess.graph.get_tensor_by_name('X_content:0')
output_tensor = sess.graph.get_tensor_by_name('add_37:0')
start_time = time.time()
ret =sess.run(output_tensor, feed_dict={input_differ:2,input_tensor:[X]})
end_time = time.time()

# TODO:完成Numpy版本 Pb模型的推理
input_tensor = sess.graph.get_tensor_by_name('X_content:0')
input_differ = sess.graph.get_tensor_by_name('moments_15/PowerDifference:0')
output_tensor = sess.graph.get_tensor_by_name('add_37:0')
conv_tensor = sess.graph.get_tensor_by_name('Conv2D_13:0')
grad_tensor = sess.graph.get_tensor_by_name('moments_15/StopGradient:0')
temp_feed = {input_differ:[X],input_tensor:[X]}
conv = sess.run(conv_tensor,feed_dict=temp_feed)
grad = sess.run(grad_tensor,feed_dict=temp_feed)
differ = power_diff_numpy(conv,grad,2)
start_time = time.time()
ret =sess.run(output_tensor, feed_dict= {input_differ:differ,input_tensor:[X]})
end_time = time.time()
```

执行结果

![Screen Shot 2021-12-17 at 12.21.05 PM](/Users/shentao/Library/Application Support/typora-user-images/Screen Shot 2021-12-17 at 12.21.05 PM.png)

![Screen Shot 2021-12-17 at 12.21.29 PM](/Users/shentao/Library/Application Support/typora-user-images/Screen Shot 2021-12-17 at 12.21.29 PM.png)

![Screen Shot 2021-12-17 at 12.21.47 PM](/Users/shentao/Library/Application Support/typora-user-images/Screen Shot 2021-12-17 at 12.21.47 PM.png)

- 原算子int8模型C++执行时间：1.78s

<img src="/Users/shentao/Library/Application Support/typora-user-images/Screen Shot 2021-12-17 at 12.23.16 PM.png" alt="Screen Shot 2021-12-17 at 12.23.16 PM" style="zoom:50%;" />

- 自定义算子int8模型C++执行时间：1.63s

<img src="/Users/shentao/Library/Application Support/typora-user-images/Screen Shot 2021-12-17 at 12.23.37 PM.png" alt="Screen Shot 2021-12-17 at 12.23.37 PM" style="zoom:50%;" />

- numpy算子int8模型执行时间：1.64s

<img src="/Users/shentao/Library/Application Support/typora-user-images/Screen Shot 2021-12-17 at 12.23.54 PM.png" alt="Screen Shot 2021-12-17 at 12.23.54 PM" style="zoom:50%;" />

### 离线推理程序

在执行MLU在线推理时，通过配置文件生成并保存两种离线模型( 原始模型、PowerDifference 算子模型) 至

/opt/AICSE-demo-student/demo/style_transfer_bcl/models/offline_models文件夹下。补全CNRT离线推理模型代码:

/opt/AICSE-demo-student/demo/style_transfer_bcl/src/offline/src/inference.cpp 然后编译并执行离线推理。

#### inference.cpp

补全cpp文件

```c++
#include "inference.h"
#include "cnrt.h"
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include "stdlib.h"
#include <sys/time.h>
#include <time.h>

namespace StyleTransfer{

typedef unsigned short half;

void cnrtConvertFloatToHalfArray(uint16_t* x, const float* y, int len) {
  for (int i = 0; i < len; i++){
    cnrtConvertFloatToHalf(x+i,y[i]);
  }
}

void cnrtConvertHalfToFloatArray(float* x, const uint16_t* y, int len) {
  for (int i = 0; i < len; i++){
    cnrtConvertHalfToFloat(x+i,y[i]);
  }
}

void cnrtConvertFloatToHalfArray(uint16_t* x, float* y, int len) {
  for (int i = 0; i < len; i++){
    cnrtConvertFloatToHalf(x+i,y[i]);
  }
}

void cnrtConvertHalfToFloatArray(float* x, uint16_t* y, int len) {
  for (int i = 0; i < len; i++){
    cnrtConvertHalfToFloat(x+i,y[i]);
  }
}


Inference :: Inference(std::string offline_model){
    offline_model_ = offline_model;
}

void Inference :: run(DataTransfer* DataT){
    cnrtInit(0);
    // load model
    cnrtModel_t model;
    cnrtLoadModel(&model, offline_model_.c_str());

    // set current device
    cnrtDev_t dev;
    cnrtGetDeviceHandle(&dev, 0);
    cnrtSetCurrentDevice(dev);
    
    float* input_data = reinterpret_cast<float*>(malloc(256*256*3*sizeof(float)));
    float* output_data = reinterpret_cast<float*>(malloc(256*256*3*sizeof(float)));
    int t = 256*256;
    for(int i=0;i<t;i++)
        for(int j=0;j<3;j++)
            input_data[i*3+j] = DataT->input_data[t*j+i];    
    //float sum;    
    //FILE *fp;
    //fp = fopen("data.txt","w");
    //if(fp == NULL){
    //	printf("file cann't open!\n");
    //    exit(0);
    //}
    //for(int i=0;i<256*256*3;i++){
    //    sum += input_data[i];
    //	fprintf(fp,"%f\t",input_data[i]);
    //}
    //fclose(fp);
    //printf("the mean of img is : %f\n",sum/(256*256*3));
    printf("the number of the second: %f\n",input_data[1]);    
    //printf("the number of the second: %f\n",DataT->input_data[256*256+258]);    
    int number = 0;
    cnrtGetFunctionNumber(model, &number);
    printf("%d function\n", number);

    // load extract function
    cnrtFunction_t function;
    if (CNRT_RET_SUCCESS != cnrtCreateFunction(&function)) {
      printf("cnrtCreateFunction Failed!\n");
      exit(-1);
    }
    
    if (CNRT_RET_SUCCESS != cnrtExtractFunction(&function, model, "subnet0")) {
      printf("cnrtExtractFunction Failed!\n");
      exit(-1);
    }
    

    int inputNum, outputNum;
    int64_t *inputSizeS, *outputSizeS;
    cnrtGetInputDataSize(&inputSizeS, &inputNum, function);
    cnrtGetOutputDataSize(&outputSizeS, &outputNum, function);  // prepare data on cpu
    printf("the input num :%d , the output num : %d\n",inputNum,outputNum);
    printf("the input size: %ld, the output size : %ld\n",inputSizeS[0],outputSizeS[0]);

    DataT->output_data = reinterpret_cast<float*>(malloc(256 * 256 * 3 * sizeof(float)));
    half* input_half = (half*)malloc(256 * 256 * 3 * sizeof(half));
    half* output_half = (half*)malloc(256 * 256 * 3 * sizeof(half));
  
    cnrtConvertFloatToHalfArray(input_half, input_data, 256 * 256 * 3);
    cnrtConvertFloatToHalfArray(output_half, DataT->output_data, 256 * 256 * 3);
  
  

    // allocate I/O data memory on MLU
    void *mlu_input, *mlu_output;

    // prepare input buffer
    if (CNRT_RET_SUCCESS != cnrtMalloc(&(mlu_input), inputSizeS[0])) {
      printf("cnrtMalloc Failed!\n");
      exit(-1);
    }
    if (CNRT_RET_SUCCESS != cnrtMalloc(&(mlu_output), outputSizeS[0])) {
      printf("cnrtMalloc output Failed!\n");
      exit(-1);
    }
    if (CNRT_RET_SUCCESS != cnrtMemcpy(mlu_input, input_half, 256 * 256 * 3 * sizeof(half), CNRT_MEM_TRANS_DIR_HOST2DEV)) {
      printf("cnrtMemcpy Failed!\n");
      exit(-1);
    }
    

    // setup runtime ctx
    cnrtRuntimeContext_t ctx;
    cnrtCreateRuntimeContext(&ctx, function, NULL);

    // bind device
    cnrtSetRuntimeContextDeviceId(ctx, 0);
    cnrtInitRuntimeContext(ctx, NULL);
    
    void *param[2];
    param[0] = mlu_input;
    param[1] = mlu_output;
    // compute offline
    cnrtQueue_t queue;
    cnrtRuntimeContextCreateQueue(ctx, &queue);
    cnrtInvokeRuntimeContext(ctx, (void**)param, queue, nullptr);
    cnrtSyncQueue(queue);
    
    printf("run success\n");
    
    if (CNRT_RET_SUCCESS != cnrtMemcpy(output_half, mlu_output, 256 * 256 * 3 * sizeof(half), CNRT_MEM_TRANS_DIR_DEV2HOST)) {
      printf("cnrtMemcpy output Failed!\n");
      exit(-1);
    }
    cnrtConvertHalfToFloatArray(output_data, output_half, 256 * 256 * 3);
    printf("memcpy output success\n");
    for(int i=0;i<t;i++)
        for(int j=0;j<3;j++)
            DataT->output_data[t*j+i] = output_data[i*3+j];

    // free memory spac
    if (CNRT_RET_SUCCESS != cnrtFree(mlu_input)) {
      printf("cnrtFree Failed!\n");
      exit(-1);
    }
    if (CNRT_RET_SUCCESS != cnrtFree(mlu_output)) {
      printf("cnrtFree output Failed!\n");
      exit(-1);
    }
    printf("free mlu success\n");
    if (CNRT_RET_SUCCESS != cnrtDestroyQueue(queue)) {
      printf("cnrtDestroyQueue Failed!\n");
      exit(-1);
    }
    printf("free queue success\n");
    cnrtDestroy();
    //free(param);
    free(input_half);
    free(output_half);
}

} // namespace StyleTransfer
```

执行结果

<img src="/Users/shentao/Library/Application Support/typora-user-images/Screen Shot 2021-12-17 at 12.30.00 PM.png" alt="Screen Shot 2021-12-17 at 12.30.00 PM" style="zoom:50%;" />

- 原算子int8模型C++执行时间：0.09s

<img src="/Users/shentao/Library/Application Support/typora-user-images/Screen Shot 2021-12-17 at 12.31.38 PM.png" alt="Screen Shot 2021-12-17 at 12.31.38 PM" style="zoom:50%;" />

- 自定义算子int8模型C++执行时间：0.07s

<img src="/Users/shentao/Library/Application Support/typora-user-images/Screen Shot 2021-12-17 at 12.32.06 PM.png" alt="Screen Shot 2021-12-17 at 12.32.06 PM" style="zoom:50%;" />

## 实验心得

### 精度损失对结果的影响

![Screen Shot 2021-12-17 at 12.32.54 PM](/Users/shentao/Library/Application Support/typora-user-images/Screen Shot 2021-12-17 at 12.32.54 PM.png)

#### 结论

- 在实验条件下，半精度算子模型与全精度算子模型的结果无明显区别。
- int8轻量化过程对结果影响较大
- 是否为离线模型对结果有一定影响，但不显著

#### 原因

- 实验过程中离线模型中使用的是int8模型针对测试图片训练后所得的模型。故对于离线模型，测试图片与训练图片实际为同一张，所以是否为离线模型对结果无明显影响(即是否重训练，对结果无明显影响) 
- 半精度算子与全精度算子在浮点模型上，由于浮点数小数点位置可变这一特性，半精度算子带来的损失被控制在固定的极小比例内，故无明显影响。对于int8模型，半精度算子和全精度算子的有效位数分别为32位和16位，远大于模型本身精度(8位)，故半精度算子在这种情况下的影响远小于模型本身精度损失带来的影响。 
- int8模型相对于浮点数模型，由于有效位数和小数点固定不可变的原因损失较大。

### 加速比

<img src="/Users/shentao/Library/Application Support/typora-user-images/Screen Shot 2021-12-17 at 12.35.30 PM.png" alt="Screen Shot 2021-12-17 at 12.35.30 PM" style="zoom:50%;" />

#### MLU+int8对比cpu+float

<img src="/Users/shentao/Library/Application Support/typora-user-images/Screen Shot 2021-12-17 at 12.36.18 PM.png" alt="Screen Shot 2021-12-17 at 12.36.18 PM" style="zoom:50%;" />

mlu+int8带来的加速比 ，结合上一个实验中mlu对比cpu加速比 ， 可知int8模型在mlu上进行运算可以带来比float模型更好的性能。

#### 自定义算子对比原算子

<img src="/Users/shentao/Library/Application Support/typora-user-images/Screen Shot 2021-12-17 at 12.37.20 PM.png" alt="Screen Shot 2021-12-17 at 12.37.20 PM" style="zoom:50%;" />

自定义算子带来的加速比1.125约等于第一次实验中自定义算子带来的加速比1.10，两次实验结果互为验证

#### 自定义算子对比numpy算子

<img src="/Users/shentao/Library/Application Support/typora-user-images/Screen Shot 2021-12-17 at 12.38.39 PM.png" alt="Screen Shot 2021-12-17 at 12.38.39 PM" style="zoom:50%;" />

- 自定义算子对比numpy算子的加速比由原来第一次实验中的有了巨大的减少，现在几乎与numpy算子相当。

- 原因在于第一次实验中numpy算子以解释方式运行在python环境下，第二次实验中numpy算子先被编译为二进制代码才被执行。其中的差距来自编译器的优化，和解释器的额外开销。 可见高级语言中编译器优化的重要性。

- 另一方面numpy算子在cpu上执行相交于自定义算子所需时间更短，这代表着自定义算子所用算法相交于高性能科学运算库的算法还有待优化。

### MLU性能优化

```bash
1. config.mlu_options.data_parallelism = 8
2. config.mlu_options.model_parallelism = 4
```

通过修改配置，使mlu同时处理8条数据流和4个模型，充分利用mlu的32个核心提高性能。